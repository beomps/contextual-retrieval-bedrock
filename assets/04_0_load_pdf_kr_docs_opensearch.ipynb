{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAG without Contextual Retrieval\n",
    "\n",
    "Anthropic의 Contextual Retrieval의 개념을 이용해서 Chunk에 Contextual 파라미터를 추가하여 Retrieve 하는 노트북입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [중요] 사전 실행 노트북\n",
    "이 노트북은 아래 두개의 셋업 노트북이 먼저 실행이 되어야 합니다.\n",
    "- (1) Setup 노트북\n",
    "    - 경로는 aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/00_setup/setup.ipynb 와 같습니다.\n",
    "    -  [Setup Notebook](https://github.com/aws-samples/aws-ai-ml-workshop-kr/blob/master/genai/aws-gen-ai-kr/00_setup/setup.ipynb)\n",
    "- (2) Amazon OpenSearch 설치 노트북    \n",
    "    - 경로는 aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/00_setup/setup_opensearch.ipynb 와 같습니다.\n",
    "    - [Setup OpenSearch](https://github.com/aws-samples/aws-ai-ml-workshop-kr/blob/master/genai/aws-gen-ai-kr/00_setup/setup_opensearch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python path: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot is added\n",
      "sys.path:  ['/home/ec2-user/anaconda3/envs/python3/lib/python310.zip', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload', '', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages', '/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot']\n",
      "python path: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr is added\n",
      "sys.path:  ['/home/ec2-user/anaconda3/envs/python3/lib/python310.zip', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload', '', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages', '/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot', '/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "def add_python_path(module_path):\n",
    "    if os.path.abspath(module_path) not in sys.path:\n",
    "        sys.path.append(os.path.abspath(module_path))\n",
    "        print(f\"python path: {os.path.abspath(module_path)} is added\")\n",
    "    else:\n",
    "        print(f\"python path: {os.path.abspath(module_path)} already exists\")\n",
    "    print(\"sys.path: \", sys.path)\n",
    "\n",
    "module_path = \"..\"\n",
    "add_python_path(module_path)\n",
    "module_path = \"../../..\"\n",
    "add_python_path(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Claude-V2-1': 'anthropic.claude-v2:1',\n",
      " 'Claude-V3-5-Sonnet': 'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
      " 'Claude-V3-Haiku': 'anthropic.claude-3-haiku-20240307-v1:0',\n",
      " 'Claude-V3-Opus': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
      " 'Claude-V3-Sonnet': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
      " 'Cohere-Embeddings-En': 'cohere.embed-english-v3',\n",
      " 'Cohere-Embeddings-Multilingual': 'cohere.embed-multilingual-v3',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Command-Light': 'cohere.command-light-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-Embeddings-V2': 'amazon.titan-embed-text-v2:0',\n",
      " 'Titan-Text-G1': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Express': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Light': 'amazon.titan-text-lite-v1',\n",
      " 'Titan-Text-G1-Premier': 'amazon.titan-text-premier-v1:0'}\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_community.chat_models import BedrockChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x7f804d2a9ab0>, region_name=None, credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_emb = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=bedrock_info.get_model_id(\n",
    "        model_name=\"Titan-Text-Embeddings-V2\"\n",
    "    )\n",
    ")\n",
    "dimension = 1024\n",
    "llm_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.데이터 준비 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  AWS Bedrock 영문 메뉴얼 사용\n",
    "### PDF Files Loading with PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf4llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF를 파싱해서 Markdown file로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "md_text = pymupdf4llm.to_markdown(\"./data/aws/bedrock-ug.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown file로 잘 변화되었는지를 확인하기 위해서 화면으로 display해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarkDown 파일을 목차별로 split합니다.\n",
    "- 기현님이 split한 방식으로 바꿔야 할지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 몇개의 docuement로 split되었는지 출력해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(md_header_splits):\n",
    "    print(\"[Header Doc Index]\", index, \"------------------------\")\n",
    "    print(\"  Header 1: \", doc.metadata['Header 1'])\n",
    "    \n",
    "    if 'Header 2' in doc.metadata :\n",
    "        print(\"    Header 2: \", doc.metadata['Header 2'])\n",
    "    \n",
    "    print(\"      [Doc page_content]:\", doc.page_content)\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child Chunk 생성\n",
    "### RecursiveCharacterTextSplitter를 이용해서 RAG로 사용할 수 있도록 child chunk로 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Char-level splits\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 250\n",
    "chunk_overlap = 30\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Chunk를 생성합니다.\n",
    "목차별로 나눠진 chunk (parent chunk)의 맨 뒷부분에 child chunk를 머지해서 Contextual Chunk를 생성합니다.\n",
    "그리고 나서 해당 Chunk를 page_content로 업데이트해서 저장합니다.\n",
    "LLM을 돌려서 parent chunk에 대한 요약문을 Contextual chunk로 저장하게 변경이 필요. 아니면 기현님 코드로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = []\n",
    "\n",
    "for index, parent_doc in enumerate(md_header_splits):\n",
    "    print(\"[Parent Doc Index]\", index, \"------------------------\")\n",
    "    print(\"--> parent_doc.metadata: \", parent_doc.metadata)\n",
    "    parent_page_content = parent_doc.page_content\n",
    "    print(\"--> parent_page_content:\", parent_page_content)\n",
    "    \n",
    "    child_docs = text_splitter.split_documents([parent_doc])\n",
    "    \n",
    "    for child_doc in child_docs:\n",
    "        original_child_chunk = child_doc.page_content\n",
    "        contexual_child_chunk = parent_page_content + ' Merge from Here. ' + original_child_chunk\n",
    "        child_doc.page_content = contexual_child_chunk\n",
    "        print(\"----> original_child_chunk: \", original_child_chunk)\n",
    "        print(\"----> contexual_child_chunk: \", contexual_child_chunk)\n",
    "        \n",
    "    splits = splits + child_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#splits\n",
    "### 몇개의 청크로 생성되었는지 출력해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(splits):\n",
    "    print(\"[Header Doc Index]\", index, \"------------------------\")\n",
    "    print(\"  Header 1: \", doc.metadata['Header 1'])\n",
    "    \n",
    "    if 'Header 2' in doc.metadata :\n",
    "        print(\"    Header 2: \", doc.metadata['Header 2'])\n",
    "    \n",
    "    print(\"      [Doc page_content]:\", doc.page_content)\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Index 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index 이름 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index_name = <your index>\n",
    "index_name = \"v1-contextual\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save reranker endpoint to Parameter Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from local_utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region=boto3.Session().region_name\n",
    "pm = parameter_store(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter stored successfully.\n"
     ]
    }
   ],
   "source": [
    "pm.put_params(\n",
    "    key=\"opensearch_index_name\",\n",
    "    value=f'{index_name}',\n",
    "    overwrite=True,\n",
    "    enc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Index 스키마 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_body = {\n",
    "    'settings': {\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                'my_analyzer': {\n",
    "                         'char_filter':['html_strip'],\n",
    "                    'tokenizer': 'nori',\n",
    "                    'filter': [\n",
    "                        #'nori_number',\n",
    "                        #'lowercase',\n",
    "                        #'trim',\n",
    "                        'my_nori_part_of_speech'\n",
    "                    ],\n",
    "                    'type': 'custom'\n",
    "                }\n",
    "            },\n",
    "            'tokenizer': {\n",
    "                'nori': {\n",
    "                    'decompound_mode': 'mixed',\n",
    "                    'discard_punctuation': 'true',\n",
    "                    'type': 'nori_tokenizer'\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"my_nori_part_of_speech\": {\n",
    "                    \"type\": \"nori_part_of_speech\",\n",
    "                    \"stoptags\": [\n",
    "                        \"J\", \"XSV\", \"E\", \"IC\",\"MAJ\",\"NNB\",\n",
    "                        \"SP\", \"SSC\", \"SSO\",\n",
    "                        \"SC\",\"SE\",\"XSN\",\"XSV\",\n",
    "                        \"UNA\",\"NA\",\"VCP\",\"VSV\",\n",
    "                        \"VX\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'index': {\n",
    "            'knn': True,\n",
    "            'knn.space_type': 'cosinesimil'  # Example space type\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'metadata': {\n",
    "                'properties': {\n",
    "                    'source': {'type': 'keyword'},\n",
    "                    'row': {'type': 'long'},\n",
    "                    'type': {'type': 'keyword'},\n",
    "                    'timestamp': {'type': 'float'},\n",
    "                }\n",
    "            },\n",
    "            'text': {\n",
    "                'analyzer': 'my_analyzer',\n",
    "                'search_analyzer': 'my_analyzer',\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'vector_field': {\n",
    "                'type': 'knn_vector',\n",
    "                'dimension': f\"{dimension}\" # Replace with your vector dimension\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. LangChain OpenSearch VectorStore 생성 \n",
    "### 선수 조건\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [중요] 아래에 aws parameter store 에 아래 인증정보가 먼저 입력되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region=boto3.Session().region_name\n",
    "pm = parameter_store(region)\n",
    "\n",
    "opensearch_domain_endpoint = pm.get_params(\n",
    "    key=\"opensearch_domain_endpoint\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_id = pm.get_params(\n",
    "    key=\"opensearch_user_id\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_password = pm.get_params(\n",
    "    key=\"opensearch_user_password\",\n",
    "    enc=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = opensearch_domain_endpoint\n",
    "rag_user_name = opensearch_user_id\n",
    "rag_user_password = opensearch_user_password\n",
    "\n",
    "http_auth = (rag_user_name, rag_user_password) # Master username, Master password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from local_utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "\n",
    "os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "    aws_region,\n",
    "    opensearch_domain_endpoint,\n",
    "    http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오픈 서치 인덱스 생성 \n",
    "- 오픈 서치에 해당 인덱스가 존재하면, 삭제 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from local_utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name=v1-faq-shinhan-bank, exists=False\n",
      "\n",
      "Creating index:\n",
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'v1-faq-shinhan-bank'}\n",
      "Index is created\n",
      "{'v1-faq-shinhan-bank': {'aliases': {},\n",
      "                         'mappings': {'properties': {'metadata': {'properties': {'row': {'type': 'long'},\n",
      "                                                                                 'source': {'type': 'keyword'},\n",
      "                                                                                 'timestamp': {'type': 'float'},\n",
      "                                                                                 'type': {'type': 'keyword'}}},\n",
      "                                                     'text': {'analyzer': 'my_analyzer',\n",
      "                                                              'type': 'text'},\n",
      "                                                     'vector_field': {'dimension': 1024,\n",
      "                                                                      'type': 'knn_vector'}}},\n",
      "                         'settings': {'index': {'analysis': {'analyzer': {'my_analyzer': {'char_filter': ['html_strip'],\n",
      "                                                                                          'filter': ['my_nori_part_of_speech'],\n",
      "                                                                                          'tokenizer': 'nori',\n",
      "                                                                                          'type': 'custom'}},\n",
      "                                                             'filter': {'my_nori_part_of_speech': {'stoptags': ['J',\n",
      "                                                                                                                'XSV',\n",
      "                                                                                                                'E',\n",
      "                                                                                                                'IC',\n",
      "                                                                                                                'MAJ',\n",
      "                                                                                                                'NNB',\n",
      "                                                                                                                'SP',\n",
      "                                                                                                                'SSC',\n",
      "                                                                                                                'SSO',\n",
      "                                                                                                                'SC',\n",
      "                                                                                                                'SE',\n",
      "                                                                                                                'XSN',\n",
      "                                                                                                                'XSV',\n",
      "                                                                                                                'UNA',\n",
      "                                                                                                                'NA',\n",
      "                                                                                                                'VCP',\n",
      "                                                                                                                'VSV',\n",
      "                                                                                                                'VX'],\n",
      "                                                                                                   'type': 'nori_part_of_speech'}},\n",
      "                                                             'tokenizer': {'nori': {'decompound_mode': 'mixed',\n",
      "                                                                                    'discard_punctuation': 'true',\n",
      "                                                                                    'type': 'nori_tokenizer'}}},\n",
      "                                                'creation_date': '1726718846141',\n",
      "                                                'knn': 'true',\n",
      "                                                'knn.space_type': 'cosinesimil',\n",
      "                                                'number_of_replicas': '1',\n",
      "                                                'number_of_shards': '5',\n",
      "                                                'provided_name': 'v1-faq-shinhan-bank',\n",
      "                                                'replication': {'type': 'DOCUMENT'},\n",
      "                                                'uuid': 'bVto8zsZTYeBNTvujYpJbg',\n",
      "                                                'version': {'created': '136327827'}}}}}\n"
     ]
    }
   ],
   "source": [
    "index_exists = opensearch_utils.check_if_index_exists(\n",
    "    os_client,\n",
    "    index_name\n",
    ")\n",
    "\n",
    "if index_exists:\n",
    "    opensearch_utils.delete_index(\n",
    "        os_client,\n",
    "        index_name\n",
    "    )\n",
    "\n",
    "opensearch_utils.create_index(os_client, index_name, index_body)\n",
    "index_info = os_client.indices.get(index=index_name)\n",
    "print(\"Index is created\")\n",
    "pprint(index_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 랭체인 인덱스 연결 오브젝트 생성\n",
    "\n",
    "- [langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.opensearch_vector_search.OpenSearchVectorSearch at 0x7f80201eb7c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    "    is_aoss=False,\n",
    "    engine=\"faiss\",\n",
    "    space_type=\"l2\",\n",
    "    bulk_size=100000,\n",
    "    timeout=60\n",
    ")\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch 에 문서 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 265 ms, sys: 13.2 ms, total: 278 ms\n",
      "Wall time: 7.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['08f687b9-c15e-4e7e-9b53-e2962bb97b5e',\n",
       " '83a36e8b-61ac-4425-ae31-7a229c223851',\n",
       " '31968754-faee-4467-890a-f8e0cee87f9f',\n",
       " '6ea8a0cc-b07f-4197-9c3c-79c45d4f2f95',\n",
       " 'f84f0838-f77d-4fcd-b72b-5526c8ccd71b',\n",
       " 'd35b7455-fa4b-451f-b385-01de66cde525',\n",
       " '4eac2269-4983-4e2f-a0f4-f23cae523047',\n",
       " '8bec0adc-01c1-43dc-bd7f-d165155307e1',\n",
       " '93ea7930-153d-45bb-8596-66077a2e6a73',\n",
       " '2c100d45-daba-4c0c-b942-3458b46d4406',\n",
       " '8af4cfec-818d-4859-8ee3-f4d68be5e617',\n",
       " '046af869-5513-4cd9-ba8a-5fad0b853fe3',\n",
       " 'ad490b3e-8572-4376-8805-cf03840074fd',\n",
       " '99dbef81-b6a0-4842-bbba-70fc0bd9ab15',\n",
       " '99c8cdd6-39a2-48cd-931e-7502a8cb9577',\n",
       " '14146182-5585-4a87-bb20-629bb69ca69b',\n",
       " 'be2f068c-cd29-4a72-8a89-426fbc0362b0',\n",
       " '37faf4f6-2b96-4fa4-8798-fb0eb058a02e',\n",
       " '037b120c-8913-4408-beff-8acff58a04fe',\n",
       " 'be41387e-20e8-4789-af06-4ffcb95df102',\n",
       " '5a8288e4-1e9c-4a85-84c1-4f0e9de084a0',\n",
       " 'cef15451-7fb2-4a33-87c6-aa42c521b337',\n",
       " '0180a16a-e1cc-4f6a-be1a-a80963f5067c',\n",
       " '6ae47fbc-fe65-4ba3-ab03-271316e90d70',\n",
       " '77663663-c073-4438-8b3f-460c236fcec1',\n",
       " '35a163c6-6de5-430e-9f62-6bc4a0adee47',\n",
       " 'a66320d8-f5af-4d8f-94bf-8b0143043439',\n",
       " 'bda72287-af17-444a-ba2b-188e7de1d2cf',\n",
       " 'ac573380-8dcd-4df2-a658-29e1eca69cf4',\n",
       " 'd47a8062-20b6-40a5-8c99-e28503de50a4',\n",
       " 'b112f7ca-aec6-478e-b8c2-b247850d0559',\n",
       " 'ff83dad2-2d34-474b-9e79-9cab15b560c9',\n",
       " 'b16ee621-7905-4c4a-b8e4-f3ab126e74b2',\n",
       " 'e7c323ae-a6e9-43c0-862a-b1493bb725de',\n",
       " '782e4cf4-1dc2-4948-a7f0-b96a2ae6a9f8',\n",
       " '1b2080e2-a83e-4202-936c-0355e6c1f813',\n",
       " '4ce5782f-0eac-4e87-a78b-30b800095ffe',\n",
       " 'b9cf6e6e-73a9-4217-944f-0a1ccac95744',\n",
       " '1314ec92-accf-4fff-a78a-4f9e4e38c2fa',\n",
       " 'e4d96563-55b9-49bd-9037-f44255a5d425',\n",
       " '99ac627d-69ec-4c31-8e36-a66f78a54caf',\n",
       " '2ac9b298-590f-402e-b269-5cbcbe91d59e',\n",
       " '183a0f83-3bc1-4945-9ad0-53854ef6e82f',\n",
       " '78f9a87d-557a-42ec-b0fc-f10f8993e4fc',\n",
       " 'e09025b7-b554-43b1-8d8c-8e3850a92d5d',\n",
       " '71b9f6bc-787c-4d4c-83c6-a86a0b62fed5',\n",
       " '8d0e9fb4-ca6f-4703-9a28-ceedf4199000',\n",
       " 'd7cb4b5c-052f-4514-9743-ef619dc5b672',\n",
       " '9c8cdb4e-2c9d-4cea-b184-7a82fc7a4f6e',\n",
       " '5366eaad-a478-418f-80ca-06be6b1f0cda',\n",
       " '4a5b5c42-f866-44ce-82d7-fb87c017ec58',\n",
       " '719c6af3-1ca8-482e-acc2-c133bfeddb42',\n",
       " 'd8750e16-31be-4049-8d83-0559007f8935',\n",
       " 'f3115850-607b-4cbd-b708-0ec0ccd8faea',\n",
       " '4c7d32da-de11-4483-9546-bb717b95bfd5',\n",
       " 'bd7286ae-ab63-457d-b2dc-550f45b3099b',\n",
       " '51b92fa8-93ce-43ce-b76e-27153eac410d',\n",
       " 'f7c7163b-86ad-43ad-ad4f-8ccdadf01c02',\n",
       " 'f193ebb1-7fe1-4c27-b956-9d565194a28a',\n",
       " 'e7fffe70-bc03-42fe-a25c-a957400852e2',\n",
       " '811cf782-ad9f-4f09-a137-05c91de6dd97',\n",
       " 'ae99cb7b-ce98-4c2d-8fa1-510653f7b0ca',\n",
       " '90011b29-9fc3-4e47-89c3-c3e2e1a60e36',\n",
       " '0525f34e-972a-41b2-93a7-f39056a568fb',\n",
       " '389ee7ff-3aad-461c-9712-8482d32c72be',\n",
       " '4fe87e3e-b60a-4036-b202-01cb3447ea82',\n",
       " 'adc4c24f-e9ca-4e1b-a0f9-9010970b5951',\n",
       " 'bb5aeb2f-c0d1-4db0-b4b2-ba2df1157bc9',\n",
       " 'c109c0c8-8dc1-4240-a732-3d12c6733041',\n",
       " '54656009-1715-4c0b-b096-bc26863e1978',\n",
       " '352aa03d-ef38-4261-ba89-98f8d2057479',\n",
       " 'ac275d23-b475-4ff3-a56d-b7337bec9231',\n",
       " 'c7d625b7-37a9-4e01-a10d-ca548fbd6b73',\n",
       " '75309d07-055f-4b94-8679-f11e2381a6bd',\n",
       " '5cc622d3-c00b-4cee-986f-ca7e91193c6c',\n",
       " '3208b612-467d-4af7-a867-13980f87e968',\n",
       " 'c7fae9ac-6b36-4149-8616-74a37bd85fc7',\n",
       " '1c03e5c3-495b-4a7a-a2d1-711d1d883df9',\n",
       " 'be845e63-64d7-42e9-979d-4ad6f7f957da',\n",
       " '94b56581-e5f5-4163-b482-901828b0f3c8',\n",
       " '17986c55-25d4-4532-abf4-5c8b37f4ad07',\n",
       " '1793b1d3-6789-4cfc-bdc9-b78b46d8dba6',\n",
       " '0e6d6312-7ec0-4cd3-b1ed-0a192ba27789',\n",
       " 'd2a1b6c6-679d-4b06-a26f-103f377ef0bd',\n",
       " 'b8fade25-29e0-41a5-a8bf-c912166cd59e',\n",
       " '2eb4d2c1-0767-41d7-84ce-e1f53c76147b',\n",
       " '65735b75-8fe2-4fe3-8f8f-77bccb41fad7',\n",
       " '9bed5858-e2cb-4530-8b95-60cf7c4c22dd',\n",
       " 'a9a494aa-4abe-4840-9272-b92c0ef55dca',\n",
       " 'e59a3fbe-1c34-4c0a-a76c-dee94acb49a8',\n",
       " '92281f6a-55ed-45d7-a283-6bc363e6ac14',\n",
       " '4bae8ec2-b918-4a1d-91d5-4813b7b4eef7']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vector_db.add_documents(\n",
    "    documents = chunk_docs, \n",
    "    vector_field = \"vector_field\",\n",
    "    bulk_size = 1000000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 검색 및 질의 응답 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import retriever_utils\n",
    "from utils.rag import show_context_used\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23968/3961750981.py:1: LangChainDeprecationWarning: The class `BedrockChat` was deprecated in LangChain 0.0.34 and will be removed in 1.0. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import ChatBedrock`.\n",
      "  llm_text = BedrockChat(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BedrockChat(client=<botocore.client.BedrockRuntime object at 0x7f804d2a9ab0>, model_id='anthropic.claude-3-haiku-20240307-v1:0', model_kwargs={'max_tokens': 1024, 'temperature': 0, 'top_p': 0.9, 'stop_sequences': ['\\n\\nHuman']}, streaming=True, callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f801e9316c0>])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_text = BedrockChat(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-Haiku\"),\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\":0,\n",
    "        \"top_p\":0.9,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### QA prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "                You are a master answer bot designed to answer user's questions.\n",
    "                I'm going to give you contexts which consist of texts, tables and images.\n",
    "                Read the contexts carefully, because I'm going to ask you a question about it.\n",
    "                '''\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "\n",
    "human_prompt = [\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": '''\n",
    "                Here is the contexts as texts: <contexts>{contexts}</contexts>\n",
    "\n",
    "                Only using the context as above, answer the following question with the rules as below:\n",
    "                    - Don't insert XML tag such as <contexts> and </contexts> when answering.\n",
    "                    - Write as much as you can\n",
    "                    - Be courteous and polite\n",
    "                    - Only answer the question if you can find the answer in the contexts with certainty.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                If the answer is not in the contexts, just say \"주어진 내용에서 관련 답변을 찾을 수 없습니다.\"\n",
    "\n",
    "                '''\n",
    "    }\n",
    "]\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_template, human_message_template]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm_text | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 하이브리드 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"온디맨드 용량 예약 방식와 예약 인스턴스의 방식의 차이는 무엇입니까?\"\n",
    "\n",
    "search_filter=[\n",
    "    #{\"term\": {\"metadata.source\": \"EC2\"}},\n",
    "    #{\"term\": {\"metadata.type\": \"요금\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "similar_docs_hybrid = retriever_utils.search_hybrid(\n",
    "    query=query,\n",
    "    k=7,\n",
    "    index_name=index_name,\n",
    "    os_client=os_client,\n",
    "    filter=search_filter,\n",
    "    fusion_algorithm=\"RRF\", # [\"RRF\", \"simple_weighted\"]\n",
    "    ensemble_weights=[0.49, 0.51], # semantic, lexical\n",
    "    async_mode=True,\n",
    "    llm_emb=llm_emb,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke(\n",
    "    {\n",
    "        \"contexts\": similar_docs_hybrid,\n",
    "        \"question\": query\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n##############################\")\n",
    "print(\"query: \\n\", query)\n",
    "print(\"answer: \\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual 검색\n",
    "# 아래 코드 구현 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Building a RAG AI with OpenSearch Serverless and LangChain](https://caylent.com/blog/building-a-rag-with-open-search-serverless-and-lang-chain)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b41de70bedc0e302a3aeb58a0c77b854f2e56c8930e61a4aaa3340c96b01f1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
